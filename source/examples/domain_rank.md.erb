<h1>
  <small>HOW TO:</small>
  Domain Rank
</h1>

You've probably heard of Page Rank, the algorithm that made Google what it is today.  The basic idea behind Page Rank is straightforward: analyze all the inbound links for a given page then use it to calculate the relevance of that page. 

Let's take that same concept, but apply it to domains.  That is, we wish to determine how popular a given domain is.  We should expect "google.com" and "facebook.com" to rank near the top, and "my_corner_bakery.com" to rank near the bottom. 

Our goal in this exercise is to count the number of domains that point to other domains.  For example, if "http://foo.com/" points to "http://bar.com", then we should give "bar.com" a score of 1.  Likewise, if "http://foo.com/page_1" and "http://bar.com/page_2" point to "baz.com", then we should give "baz.com" a score of 2. 



<%= h2_link("Analyzing the Web") %>

Zillabyte makes this task a breeze.  Zillabyte handles crawling the web and running your algorithm; all you need to do is craft your algorithm in a way that Zillabyte can understand.  This is known as the [Pipe Programming Paradigm](http://blog.zillabyte.com/2014/05/14/the-pipe-programming-paradigm/), and it is what allows Zillabyte parallelize your code and process billions of records in short order. 

Let's look at the complete code ([Github Link](https://github.com/zillabyte/examples/tree/master/domain_rank)):


<%= h2_link("The Code") %>

```ruby
<%= link_file("../examples/domain_rank/app.rb") %>
```


<%= h2_link("What's Going On?") %>

The above code conforms to the pipe programming paradigm. This allows Zillabyte to parallelize the algorithm so we can get results in seconds, not days.  

The above code is broken into four parts: (a) a source, (b) a uniquer, (c) a counter, and finally (d) a sink.  Let's look at each on in detail. 


<%= h2_link("The Source") %>

All data in a app must originate from a `source`.  In this particular case, we need to tell Zillabyte what kind of data to source from.  

#### Matches and Emitting Data

A source consumes data from Zillabyte, processes it, and then passes new data to the rest of the app.  

#### The Heart of the Ranking

The next component is the `each`.  This is the block of code that actually runs on every web page. 

```ruby

links = stream.each do |tuple|  
  # This is called on every web page
  base_url = tuple['url']
  html = tuple['html']
  doc = Nokogiri::HTML(html)
  
  doc.css('a').each do |link| 
    # What domain does this item link to? 
    target_uri = URI.join( base_url, link['href'])
    target_domain = target_uri.host.downcase
    
    # Emit this to a stream.  This is important because it will allow
    # Zillabyte to parallelize the operation
    emit :source_domain => source_domain, :target_domain => target_domain
  end
end
```

The above code does the following: (a) extract the links from a web page, then (b) extract the domain of that link, then (c) emit the domain back to the stream.  Zillabyte allows you to reuse 3rd party libraries.  In this case, we're using [Nokogiri](http://nokogiri.org/) to handle our HTML parsing. 


<%= h2_link("The Uniquer") %>

As data emits from the source, we want to make sure we avoid duplication.  That is, we want to make sure a target domain only gets one point for every source domain.  Because the source can be parallelized, it makes sense to handle this logic after the source.  The following line should do the trick:

```ruby
stream.unique()
```


#### The Counter

Now we are going to instruct the app to start counting.  At this point in the app, the stream contains two fields: `[source_domain, target_domain]`.  We want to group all the `target_domains` and count the size of it. 

```
stream.count :target_domain
```

The above will group by the field `target_domain` and add a new field called `count`.  The resulting stream will contain two fields: `[target_domain, count]`


#### The Sink

All apps must come to an end.  A sink allows our new data to return to persistent storage inside Zillabyte.  This data can be downloaded later via the Zillabyte CLI.  

```ruby
web_stream.sink do |h|
  h.name "domain_rank"
  h.column "domain", :string
  h.column "score", :integer
end
```

When we sink data, we need to give Zillabyte some meta information about the data being sunk.  In the above, the sink creates a new relation called `domain_rank`.  This relation contains two columns, `domain` and `score`.  Order is important here, the first field corresponds to the first field in our stream, `target_domain`, and the second column corresponds to `count`. 


<%= h2_link("Conclusion & Next Steps ") %>

The above example shows how quickly you can analyze large chunks of the world's information.  In less than 50 lines of code, we were able to understand the popularity distribution of domains across the internet.  

To see the output & practical implications of this analysis, please check out the corresponding blog post: [The Long Tail of the Web](http://blog.zillabyte.com/2014/03/13/the-long-tail-of-the-web/)
